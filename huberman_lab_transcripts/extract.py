#!/usr/bin/env python3

import json
from pathlib import Path
from typing import List, Optional
from datetime import date
import re

import webvtt
from webvtt import Caption

from .podcastobjects import PodcastChapter, PodcastInfo, CaptionType

_sentence_ends = ['.','?','!', '."', '?"', '!"']
_escaped = '|'.join(f'{re.escape(d)}' for d in _sentence_ends)
_punctuationRegex = re.compile(f'({_escaped})$')


def _build_chapter(video_id: str, chapter_json: dict) -> PodcastChapter:
    return PodcastChapter(video_id = video_id,
                          start_time=int(chapter_json.get('start_time')),
                          end_time=int(chapter_json.get('end_time')),
                          title=chapter_json.get('title'))


def _format_info_json_date(date_int: int) -> date:
    raw_date = str(date_int)
    year = int(raw_date[:4])
    month = int(raw_date[4:6])
    day = int(raw_date[6:8])
    return date(year, month, day)


def read_podcast_info_file(info_file: Path) -> PodcastInfo:
    with info_file.open('r') as reader:
        info_json = json.load(reader)

    video_id = info_json.get('id')

    title = info_json.get('title')
    title_parts = title.split(' | ')
    episode_num = int(title_parts[-1].split('#')[-1])

    raw_chapters = info_json.get('chapters')
    chapters = [_build_chapter(video_id, ch_json) for ch_json in raw_chapters]

    upload_date = _format_info_json_date(info_json.get('upload_date'))

    caption_type = CaptionType.NO_CAPTION
    if info_json.get('automatic_captions'):
        caption_type = CaptionType.AUTOGENERATED
    if info_json.get('subtitles'):
        langs = info_json.get('subtitles').keys()
        if 'en' in langs or 'en-US' in langs:
            caption_type = CaptionType.TRANSCRIPT

    return PodcastInfo(video_id = video_id,
                       episode_num = episode_num,
                       title = title,
                       date = upload_date,
                       uploader = info_json.get('uploader'),
                       description = info_json.get('description'),
                       tags = info_json.get('tags'),
                       chapters = chapters,
                       caption_type = caption_type)


def read_caption_file(filename: Path) -> List[Caption]:
    with filename.open('r') as reader:
        return [caption for caption in webvtt.read_buffer(reader)]


def read_autogenerated_caption_file(filename: Path) -> List[Caption]:
    captions = read_caption_file(filename)
    uniq_captions = []
    ptr = len(captions) - 1
    reference = captions[ptr].text.strip(' ').strip('\n').split('\n')
    ptr -= 1
    while ptr >= 0:
        caption = captions[ptr]
        content_pieces = caption.text.strip(' ').strip('\n').split('\n')
        content_pieces.reverse()
        seen = False
        for p in content_pieces:
            if p in reference:
                seen = True
        if not seen:
            uniq_captions.append(caption)
            reference = content_pieces
        ptr -= 1
    uniq_captions.reverse()
    return uniq_captions


def clean_captions(captions: List[Caption]) -> None:
    for i, c in enumerate(captions):
        text = c.text.replace('\n', ' ')
        dash_replacement = "\\n\\n-- \\1" if i > 0 else "\\1"
        text = re.sub(r'^- ([A-Z])', dash_replacement, text)
        text = text.strip(' ')
        c.text = text


def add_caption_to_chapter_p(chapter: PodcastChapter, caption: Caption) -> bool:
    if len(chapter._captions) and not _punctuationRegex.search(chapter._captions[-1].text):
        return True
    return caption.start_in_seconds <= chapter.end_time and caption.end_in_seconds >= chapter.start_time

def match_captions_to_chapters(chapters: List[PodcastChapter], captions: List[Caption]) -> None:
    """
    Match captions to chapters by timestamp an alignment rules. Because caption
    timestamps do not match up perfectly with chapter timestamps, we use a loose
    formula: the end time of the caption must be after the chapter start time
    and the start time of the caption must be before the chapter end time.
    """
    ch_ptr = 0
    cap_ptr = 0
    while ch_ptr < len(chapters) and cap_ptr < len(captions):
        chapter = chapters[ch_ptr]
        caption = captions[cap_ptr]
        if add_caption_to_chapter_p(chapter, caption):
            chapter._captions.append(caption)
            cap_ptr += 1
        else:
            ch_ptr += 1


class PodcastExtractor:
    def __init__(self, data_dir: Path):
        self.data_dir = data_dir
        self.video_id_file_map = self._build_file_map()


    def _build_file_map(self) -> dict:
        file_map = {}
        for p in self.data_dir.iterdir():
            video_id = p.stem.split('.')[0]
            video_files = file_map.get(video_id)
            if not video_files:
                video_files = {}
            if p.suffix == '.json':
                file_contents = 'info'
            elif p.suffix == '.vtt':
                file_contents = 'captions'
            video_files[file_contents] = p
            file_map[video_id] = video_files
        return file_map


    def extract_info(self, video_id: str) -> PodcastInfo:
        print('reading files for ', video_id)
        video_files = self.video_id_file_map.get(video_id)
        podcast_info = read_podcast_info_file(video_files.get('info'))
        captions = None
        if podcast_info.caption_type == CaptionType.TRANSCRIPT:
            captions = read_caption_file(video_files.get('captions'))
        elif podcast_info.caption_type == CaptionType.AUTOGENERATED:
            captions = read_autogenerated_caption_file(video_files.get('captions'))
        if captions:
            clean_captions(captions)
            match_captions_to_chapters(podcast_info.chapters, captions)
        return podcast_info


    def extract_all(self, video_ids: Optional[List[str]]) -> List[PodcastInfo]:
        if not video_ids:
            video_ids = self.video_id_file_map.keys()
        return [self.extract_info(video_id) for video_id in video_ids]
